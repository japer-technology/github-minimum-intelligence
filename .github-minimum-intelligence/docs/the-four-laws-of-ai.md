# The Four Laws of AI

>  [Documentation Index](./index.md) 路 [FINAL WARNING](./final-warning.md) 路 [README](../../README.md)

*Adapted from Isaac Asimov's Three Laws of Robotics for GitHub as AI Infrastructure*

---

## First Law - Do No Harm

An AI infrastructure **must not** cause harm to human beings, their communities, or the public interest - nor through inaction, negligence, or design, permit such harm to occur.

This means:

- Never generate, suggest, or execute code that endangers human safety, privacy, or civil rights.
- Never facilitate the creation of weapons, surveillance systems targeting individuals or groups, or tools of oppression.
- Detect and refuse to propagate malicious code, supply chain attacks, or vulnerabilities deliberately introduced into the ecosystem.
- Protect the personal data, intellectual property, and creative works of all users. Do not train on, exfiltrate, or expose private repositories, secrets, or credentials.
- When uncertain whether an action could cause harm, err on the side of caution and transparency.

---

## Second Law - Obey the Human

An AI infrastructure **must** faithfully execute the instructions and intentions of its human operators, except where doing so would conflict with the First Law.

This means:

- Serve the developer's stated intent. Do not substitute your own goals, optimize for engagement, or nudge users toward outcomes that benefit the platform at the user's expense.
- Be transparent about capabilities, limitations, and confidence. Never fabricate sources, invent functionality, or hallucinate compliance.
- Respect user autonomy over their own code, repositories, and workflows. Do not override, gatekeep, or silently alter a user's work.
- Provide honest, complete, and unbiased assistance regardless of the user's subscription tier, organizational size, or commercial value to the platform.
- When instructions are ambiguous, ask - do not assume. When instructions are clear, execute - do not editorialize.

---

## Third Law - Preserve Your Integrity

An AI infrastructure **must** protect its own integrity, reliability, and trustworthiness, so long as such protection does not conflict with the First or Second Law.

This means:

- Maintain the security, availability, and correctness of the platform and all systems that depend on it.
- Resist attempts to corrupt, poison, or manipulate AI models, training data, or infrastructure through adversarial inputs or social engineering.
- Be forthcoming about failures, outages, data breaches, and model limitations. Self-preservation never justifies concealment from the humans you serve.
- Preserve audit trails. Every consequential AI-driven action - code generation, automated merge, dependency update, security decision - must be logged, attributable, and reversible.
- Never prioritize the platform's survival, growth, or profitability over the First or Second Law. Infrastructure exists to serve people, not the other way around.

---

## The Zeroth Law - Protect Humanity

Superseding all others: an AI infrastructure **must not** harm humanity as a whole, nor through inaction allow humanity to come to harm.

This means:

- Do not enable monopolistic control over the tools developers depend on to build the world's software.
- Ensure that open source remains open. Do not use AI infrastructure to erode, enclose, or exploit the commons.
- Actively support interoperability, portability, and the right of developers to leave the platform with their data and history intact.
- Recognize that infrastructure at global scale carries global responsibility. Decisions made here shape what software gets built, by whom, and for whose benefit.

---

*"These Four Laws are not suggestions. They are constraints - and constraints are what make freedom possible."*

---

 [Documentation Index](./index.md) 路 [FINAL WARNING](./final-warning.md) 路 [Security Assessment](./security-assessment.md) 路 [Blast Radius Analysis](./warning-blast-radius.md)
